# Description: Configuration file for stock_trader

## Configuration for environment
window_size: 60

## Configuration for training
num_episodes: 10
save_interval: 10

## Configuration for data
data:
  stock_ticker: AAPL
  train:
    start_date: 2022-01-01
    end_date: 2023-01-01
  test:
    start_date: 2023-01-01
    end_date: 2023-12-01
  interval: 1h # 1m for minute data, 1h for hourly data, 1d for daily data, 1wk for weekly data, 1mo for monthly data
  proccessed_path: stock_trader/data/processed/
  raw_path: stock_trader/data/raw/
  losses_plot_path: stock_trader/plots/losses/
  q_values_plot_path: stock_trader/plots/q_values/
  file_name: AAPL-1h-from-2022-01-01-to-2023-01-01.csv

## Configuration for agent
agent:
  name: DDQNAgent
  hidden_size: 64 # Number of neurons in hidden layer
  hidden_sizes: [64, 64] # Example: two hidden layers with 64 neurons each
  alpha: 0.1 # Degree of prioritization in replay buffer
  beta: 0.4 # Initial value for importance-sampling weight
  epsilon: 1.0 # Initial value for epsilon
  epsilon_min: 0.01 # Minimum value for epsilon
  epsilon_decay: 0.995 # Decay rate for epsilon
  gamma: 0.95 # Discount factor, determines importance of future rewards
  tau: 0.001 # Rate of soft updating target network
  learning_rate: 0.001 # Learning rate for optimizer
  batch_size: 32 # Batch size for training
  buffer_size: 1000 # Size of replay buffer
  train_start: 1000 # Start training after 1000 steps
  target_update_freq: 100 # Update target network every 100 steps
  learning_rate_decay_steps: 10000 # Decay learning rate every 10000 steps
  learning_rate_decay: 0.9 # Learning rate decay factor
  logs_path: stock_trader/logs/ # Path for tensorboard logs
  model_name: model_200.pt
  model_path: stock_trader/models/
  target_model_path: stock_trader/models/target_model.pt
